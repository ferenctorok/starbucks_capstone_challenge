{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training notebook\n",
    "\n",
    "This notebook contains the training code for the Starbucks Capstone Challenge.\n",
    "\n",
    "It has got the following structure:\n",
    "* Checking the correlation of the features in the training data\n",
    "* Based on this seleceting the sufficient features\n",
    "* Shuffleing the data\n",
    "* splitting the data into train, validation and test sets\n",
    "* creating data loaders\n",
    "* defining the models\n",
    "* finding sufficient hyperparameters\n",
    "* training the models\n",
    "* evaluating the trained models\n",
    "* compare the results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from importlib import reload\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from source import training_helpers\n",
    "from source import model\n",
    "from source.model import Linear_NN\n",
    "from source import solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is avalilabe\n"
     ]
    }
   ],
   "source": [
    "# setting up torch device:\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('cuda is avalilabe' if torch.cuda.is_available() else 'cuda is NOT avaliable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source.solver' from '/home/ferenc/Documents/Udacity/Machine_Learning_Engineer/Starbucks_Capstone_Project/source/solver.py'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(training_helpers)\n",
    "reload(model)\n",
    "reload(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the dataset and checking feature correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read training data from data/training_data_standardized.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>membership_length</th>\n",
       "      <th>av_money_spent</th>\n",
       "      <th>num_received</th>\n",
       "      <th>viewed/received</th>\n",
       "      <th>...</th>\n",
       "      <th>offer_1</th>\n",
       "      <th>offer_2</th>\n",
       "      <th>offer_3</th>\n",
       "      <th>offer_4</th>\n",
       "      <th>offer_5</th>\n",
       "      <th>offer_6</th>\n",
       "      <th>offer_7</th>\n",
       "      <th>offer_8</th>\n",
       "      <th>offer_9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.193501</td>\n",
       "      <td>1.654475</td>\n",
       "      <td>0.132255</td>\n",
       "      <td>-0.763102</td>\n",
       "      <td>-1.206595</td>\n",
       "      <td>-1.292364</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011285</td>\n",
       "      <td>-0.763102</td>\n",
       "      <td>-1.206595</td>\n",
       "      <td>-1.292364</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792728</td>\n",
       "      <td>0.253302</td>\n",
       "      <td>-1.245015</td>\n",
       "      <td>-0.763102</td>\n",
       "      <td>-1.206595</td>\n",
       "      <td>-1.292364</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.253576</td>\n",
       "      <td>-0.763102</td>\n",
       "      <td>-1.206595</td>\n",
       "      <td>-1.292364</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620969</td>\n",
       "      <td>-0.540695</td>\n",
       "      <td>-0.865163</td>\n",
       "      <td>-0.763102</td>\n",
       "      <td>-1.206595</td>\n",
       "      <td>-1.292364</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     F    M    O    U       age    income  membership_length  av_money_spent  \\\n",
       "0  1.0  0.0  0.0  0.0  1.193501  1.654475           0.132255       -0.763102   \n",
       "1  0.0  0.0  0.0  1.0  0.000000  0.000000          -0.011285       -0.763102   \n",
       "2  0.0  1.0  0.0  0.0  0.792728  0.253302          -1.245015       -0.763102   \n",
       "3  0.0  0.0  0.0  1.0  0.000000  0.000000          -0.253576       -0.763102   \n",
       "4  0.0  1.0  0.0  0.0  0.620969 -0.540695          -0.865163       -0.763102   \n",
       "\n",
       "   num_received  viewed/received  ...  offer_1  offer_2  offer_3  offer_4  \\\n",
       "0     -1.206595        -1.292364  ...        0        0        1        0   \n",
       "1     -1.206595        -1.292364  ...        0        0        0        1   \n",
       "2     -1.206595        -1.292364  ...        0        0        0        0   \n",
       "3     -1.206595        -1.292364  ...        1        0        0        0   \n",
       "4     -1.206595        -1.292364  ...        0        0        0        0   \n",
       "\n",
       "   offer_5  offer_6  offer_7  offer_8  offer_9  label  \n",
       "0        0        0        0        0        0      3  \n",
       "1        0        0        0        0        0      3  \n",
       "2        0        0        0        0        1      3  \n",
       "3        0        0        0        0        0      3  \n",
       "4        0        0        0        1        0      3  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data:\n",
    "data_dir = 'data'\n",
    "data_file = 'training_data_standardized.csv'\n",
    "training_data_df = training_helpers.load_training_data(data_dir=data_dir, data_file=data_file)\n",
    "training_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f55bf7c3070>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chceking the number of labels in the dataset:\n",
    "label_counts_df = training_data_df.label.value_counts().sort_index()\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "label_counts_df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>membership_length</th>\n",
       "      <th>av_money_spent</th>\n",
       "      <th>num_received</th>\n",
       "      <th>viewed/received</th>\n",
       "      <th>...</th>\n",
       "      <th>offer_1</th>\n",
       "      <th>offer_2</th>\n",
       "      <th>offer_3</th>\n",
       "      <th>offer_4</th>\n",
       "      <th>offer_5</th>\n",
       "      <th>offer_6</th>\n",
       "      <th>offer_7</th>\n",
       "      <th>offer_8</th>\n",
       "      <th>offer_9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.742123</td>\n",
       "      <td>-0.080854</td>\n",
       "      <td>-0.288567</td>\n",
       "      <td>0.144789</td>\n",
       "      <td>0.222408</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>0.198040</td>\n",
       "      <td>-0.004785</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>-0.004738</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.002574</td>\n",
       "      <td>-0.004166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>-0.742123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>-0.393560</td>\n",
       "      <td>-0.137893</td>\n",
       "      <td>-0.210736</td>\n",
       "      <td>-0.003784</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>-0.027004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>-0.002849</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.002820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>-0.080854</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042878</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.013558</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>-0.004134</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008012</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>-0.002745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>-0.288567</td>\n",
       "      <td>-0.393560</td>\n",
       "      <td>-0.042878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>-0.232751</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.033187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.002587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.144789</td>\n",
       "      <td>-0.137893</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300572</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>0.080883</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002082</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.005924</td>\n",
       "      <td>-0.007731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.222408</td>\n",
       "      <td>-0.210736</td>\n",
       "      <td>-0.013558</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.300572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>0.244121</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>0.028156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.005584</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>-0.002103</td>\n",
       "      <td>-0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>membership_length</th>\n",
       "      <td>0.011123</td>\n",
       "      <td>-0.003784</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176122</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.010036</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>-0.005336</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_money_spent</th>\n",
       "      <td>0.198040</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>-0.232751</td>\n",
       "      <td>0.080883</td>\n",
       "      <td>0.244121</td>\n",
       "      <td>0.176122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.313841</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.018239</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>-0.019673</td>\n",
       "      <td>-0.011763</td>\n",
       "      <td>-0.036415</td>\n",
       "      <td>0.021134</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>-0.005191</td>\n",
       "      <td>-0.029876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_received</th>\n",
       "      <td>-0.004785</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>-0.004134</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.313841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073504</td>\n",
       "      <td>0.073351</td>\n",
       "      <td>-0.030938</td>\n",
       "      <td>-0.108061</td>\n",
       "      <td>-0.024229</td>\n",
       "      <td>-0.105950</td>\n",
       "      <td>0.067890</td>\n",
       "      <td>0.069505</td>\n",
       "      <td>-0.026006</td>\n",
       "      <td>-0.107171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed/received</th>\n",
       "      <td>0.001956</td>\n",
       "      <td>-0.027004</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.033187</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>0.028156</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>0.516739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>0.022699</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>-0.035243</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>-0.042932</td>\n",
       "      <td>0.019774</td>\n",
       "      <td>0.027679</td>\n",
       "      <td>-0.005509</td>\n",
       "      <td>-0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed/viewed</th>\n",
       "      <td>0.112884</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.013580</td>\n",
       "      <td>-0.166805</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.096629</td>\n",
       "      <td>0.144729</td>\n",
       "      <td>0.530017</td>\n",
       "      <td>0.337040</td>\n",
       "      <td>0.414042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020779</td>\n",
       "      <td>0.018320</td>\n",
       "      <td>-0.007738</td>\n",
       "      <td>-0.026592</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>-0.031542</td>\n",
       "      <td>0.020129</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>-0.010146</td>\n",
       "      <td>-0.029175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed_not_viewed</th>\n",
       "      <td>0.126325</td>\n",
       "      <td>-0.025500</td>\n",
       "      <td>0.008031</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.044466</td>\n",
       "      <td>0.120203</td>\n",
       "      <td>0.062968</td>\n",
       "      <td>0.422587</td>\n",
       "      <td>0.198433</td>\n",
       "      <td>0.103660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012585</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.019720</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>-0.018375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_received_this</th>\n",
       "      <td>-0.003981</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>0.097507</td>\n",
       "      <td>0.331111</td>\n",
       "      <td>0.176541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019362</td>\n",
       "      <td>0.023672</td>\n",
       "      <td>-0.008809</td>\n",
       "      <td>-0.036359</td>\n",
       "      <td>-0.008941</td>\n",
       "      <td>-0.037468</td>\n",
       "      <td>0.025908</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>-0.005022</td>\n",
       "      <td>-0.037621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed/received_this</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.009559</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.113534</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.251604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051579</td>\n",
       "      <td>-0.025867</td>\n",
       "      <td>-0.039027</td>\n",
       "      <td>-0.071535</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>-0.015218</td>\n",
       "      <td>0.039592</td>\n",
       "      <td>0.055319</td>\n",
       "      <td>-0.037366</td>\n",
       "      <td>-0.010424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed/viewed_this</th>\n",
       "      <td>0.037950</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>-0.057935</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>0.035328</td>\n",
       "      <td>0.040501</td>\n",
       "      <td>0.171388</td>\n",
       "      <td>0.134594</td>\n",
       "      <td>0.138102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>-0.069690</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>-0.024854</td>\n",
       "      <td>0.053831</td>\n",
       "      <td>0.030239</td>\n",
       "      <td>-0.069729</td>\n",
       "      <td>0.052714</td>\n",
       "      <td>-0.001545</td>\n",
       "      <td>0.105789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed_not_viewed_this</th>\n",
       "      <td>0.037784</td>\n",
       "      <td>-0.005542</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.044390</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.126682</td>\n",
       "      <td>0.097160</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>-0.046904</td>\n",
       "      <td>0.047860</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>-0.016795</td>\n",
       "      <td>-0.046930</td>\n",
       "      <td>0.026260</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_0</th>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.001358</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>-0.010350</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>-0.011767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117737</td>\n",
       "      <td>-0.118216</td>\n",
       "      <td>-0.106681</td>\n",
       "      <td>-0.094740</td>\n",
       "      <td>-0.106043</td>\n",
       "      <td>-0.092320</td>\n",
       "      <td>-0.118282</td>\n",
       "      <td>-0.117219</td>\n",
       "      <td>-0.106820</td>\n",
       "      <td>0.179451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_1</th>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>-0.008012</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>-0.002082</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.073504</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130969</td>\n",
       "      <td>-0.118190</td>\n",
       "      <td>-0.104960</td>\n",
       "      <td>-0.117482</td>\n",
       "      <td>-0.102279</td>\n",
       "      <td>-0.131042</td>\n",
       "      <td>-0.129864</td>\n",
       "      <td>-0.118344</td>\n",
       "      <td>0.198810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_2</th>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.018239</td>\n",
       "      <td>0.073351</td>\n",
       "      <td>0.022699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.118671</td>\n",
       "      <td>-0.105388</td>\n",
       "      <td>-0.117960</td>\n",
       "      <td>-0.102695</td>\n",
       "      <td>-0.131575</td>\n",
       "      <td>-0.130393</td>\n",
       "      <td>-0.118825</td>\n",
       "      <td>-0.658765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_3</th>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>-0.030938</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118190</td>\n",
       "      <td>-0.118671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.095104</td>\n",
       "      <td>-0.106451</td>\n",
       "      <td>-0.092675</td>\n",
       "      <td>-0.118736</td>\n",
       "      <td>-0.117670</td>\n",
       "      <td>-0.107231</td>\n",
       "      <td>0.180141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_4</th>\n",
       "      <td>0.006749</td>\n",
       "      <td>-0.002849</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.019673</td>\n",
       "      <td>-0.108061</td>\n",
       "      <td>-0.035243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104960</td>\n",
       "      <td>-0.105388</td>\n",
       "      <td>-0.095104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094535</td>\n",
       "      <td>-0.082302</td>\n",
       "      <td>-0.105446</td>\n",
       "      <td>-0.104499</td>\n",
       "      <td>-0.095229</td>\n",
       "      <td>0.159977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_5</th>\n",
       "      <td>-0.004738</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.010036</td>\n",
       "      <td>-0.011763</td>\n",
       "      <td>-0.024229</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117482</td>\n",
       "      <td>-0.117960</td>\n",
       "      <td>-0.106451</td>\n",
       "      <td>-0.094535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092121</td>\n",
       "      <td>-0.118026</td>\n",
       "      <td>-0.116966</td>\n",
       "      <td>-0.106590</td>\n",
       "      <td>0.179063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_6</th>\n",
       "      <td>-0.004614</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.005584</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>-0.036415</td>\n",
       "      <td>-0.105950</td>\n",
       "      <td>-0.042932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102279</td>\n",
       "      <td>-0.102695</td>\n",
       "      <td>-0.092675</td>\n",
       "      <td>-0.082302</td>\n",
       "      <td>-0.092121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.102753</td>\n",
       "      <td>-0.101829</td>\n",
       "      <td>-0.092796</td>\n",
       "      <td>0.155891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_7</th>\n",
       "      <td>0.004370</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.021134</td>\n",
       "      <td>0.067890</td>\n",
       "      <td>0.019774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131042</td>\n",
       "      <td>-0.131575</td>\n",
       "      <td>-0.118736</td>\n",
       "      <td>-0.105446</td>\n",
       "      <td>-0.118026</td>\n",
       "      <td>-0.102753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130465</td>\n",
       "      <td>-0.118891</td>\n",
       "      <td>-0.659131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_8</th>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>-0.005336</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.069505</td>\n",
       "      <td>0.027679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129864</td>\n",
       "      <td>-0.130393</td>\n",
       "      <td>-0.117670</td>\n",
       "      <td>-0.104499</td>\n",
       "      <td>-0.116966</td>\n",
       "      <td>-0.101829</td>\n",
       "      <td>-0.130465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.117823</td>\n",
       "      <td>0.197935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_9</th>\n",
       "      <td>-0.002574</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-0.005924</td>\n",
       "      <td>-0.002103</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.005191</td>\n",
       "      <td>-0.026006</td>\n",
       "      <td>-0.005509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118344</td>\n",
       "      <td>-0.118825</td>\n",
       "      <td>-0.107231</td>\n",
       "      <td>-0.095229</td>\n",
       "      <td>-0.106590</td>\n",
       "      <td>-0.092796</td>\n",
       "      <td>-0.118891</td>\n",
       "      <td>-0.117823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>-0.004166</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>-0.003298</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-0.029876</td>\n",
       "      <td>-0.107171</td>\n",
       "      <td>-0.032227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>-0.658765</td>\n",
       "      <td>0.180141</td>\n",
       "      <td>0.159977</td>\n",
       "      <td>0.179063</td>\n",
       "      <td>0.155891</td>\n",
       "      <td>-0.659131</td>\n",
       "      <td>0.197935</td>\n",
       "      <td>0.180376</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  F         M         O         U       age  \\\n",
       "F                          1.000000 -0.742123 -0.080854 -0.288567  0.144789   \n",
       "M                         -0.742123  1.000000 -0.110272 -0.393560 -0.137893   \n",
       "O                         -0.080854 -0.110272  1.000000 -0.042878 -0.003326   \n",
       "U                         -0.288567 -0.393560 -0.042878  1.000000  0.000406   \n",
       "age                        0.144789 -0.137893 -0.003326  0.000406  1.000000   \n",
       "income                     0.222408 -0.210736 -0.013558  0.001730  0.300572   \n",
       "membership_length          0.011123 -0.003784 -0.009273 -0.007125  0.020466   \n",
       "av_money_spent             0.198040 -0.035368  0.018863 -0.232751  0.080883   \n",
       "num_received              -0.004785  0.002142 -0.004134  0.004901 -0.001565   \n",
       "viewed/received            0.001956 -0.027004  0.012073  0.033187  0.014495   \n",
       "completed/viewed           0.112884  0.002391  0.013580 -0.166805  0.046993   \n",
       "completed_not_viewed       0.126325 -0.025500  0.008031 -0.142857  0.044466   \n",
       "num_received_this         -0.003981 -0.000959  0.000132  0.006976  0.005968   \n",
       "viewed/received_this      -0.000007 -0.009559  0.002939  0.013158  0.005989   \n",
       "completed/viewed_this      0.037950  0.000828  0.010274 -0.057935  0.019797   \n",
       "completed_not_viewed_this  0.037784 -0.005542 -0.002022 -0.044390  0.015882   \n",
       "offer_0                   -0.000108 -0.001358  0.002588  0.001328 -0.002198   \n",
       "offer_1                    0.002295 -0.001056 -0.008012  0.000882 -0.002082   \n",
       "offer_2                    0.001120  0.000916  0.000654 -0.003135  0.004210   \n",
       "offer_3                   -0.000737 -0.000871  0.001314  0.001902 -0.002300   \n",
       "offer_4                    0.006749 -0.002849  0.002979 -0.006255  0.002606   \n",
       "offer_5                   -0.004738  0.003803  0.002733  0.000195 -0.000767   \n",
       "offer_6                   -0.004614  0.005320 -0.000603 -0.001151 -0.000065   \n",
       "offer_7                    0.004370 -0.004631  0.002963 -0.000275  0.005979   \n",
       "offer_8                   -0.002159 -0.000889 -0.001584  0.004855  0.000075   \n",
       "offer_9                   -0.002574  0.002432 -0.002334  0.000786 -0.005924   \n",
       "label                     -0.004166  0.002820 -0.002745  0.002587 -0.007731   \n",
       "\n",
       "                             income  membership_length  av_money_spent  \\\n",
       "F                          0.222408           0.011123        0.198040   \n",
       "M                         -0.210736          -0.003784       -0.035368   \n",
       "O                         -0.013558          -0.009273        0.018863   \n",
       "U                          0.001730          -0.007125       -0.232751   \n",
       "age                        0.300572           0.020466        0.080883   \n",
       "income                     1.000000           0.047885        0.244121   \n",
       "membership_length          0.047885           1.000000        0.176122   \n",
       "av_money_spent             0.244121           0.176122        1.000000   \n",
       "num_received              -0.006509           0.000882        0.313841   \n",
       "viewed/received            0.028156           0.006887        0.396038   \n",
       "completed/viewed           0.096629           0.144729        0.530017   \n",
       "completed_not_viewed       0.120203           0.062968        0.422587   \n",
       "num_received_this         -0.000113          -0.000080        0.097507   \n",
       "viewed/received_this       0.006739           0.002575        0.113534   \n",
       "completed/viewed_this      0.035328           0.040501        0.171388   \n",
       "completed_not_viewed_this  0.031224           0.019331        0.126682   \n",
       "offer_0                    0.001645           0.000790       -0.010350   \n",
       "offer_1                    0.003162           0.005271        0.013244   \n",
       "offer_2                    0.000764           0.000403        0.018239   \n",
       "offer_3                   -0.003768           0.004939        0.002616   \n",
       "offer_4                   -0.001267           0.000589       -0.019673   \n",
       "offer_5                   -0.000318          -0.010036       -0.011763   \n",
       "offer_6                   -0.005584           0.001721       -0.036415   \n",
       "offer_7                    0.003583           0.001926        0.021134   \n",
       "offer_8                    0.002338          -0.005336        0.016454   \n",
       "offer_9                   -0.002103          -0.000274       -0.005191   \n",
       "label                     -0.003298          -0.001767       -0.029876   \n",
       "\n",
       "                           num_received  viewed/received  ...   offer_1  \\\n",
       "F                             -0.004785         0.001956  ...  0.002295   \n",
       "M                              0.002142        -0.027004  ... -0.001056   \n",
       "O                             -0.004134         0.012073  ... -0.008012   \n",
       "U                              0.004901         0.033187  ...  0.000882   \n",
       "age                           -0.001565         0.014495  ... -0.002082   \n",
       "income                        -0.006509         0.028156  ...  0.003162   \n",
       "membership_length              0.000882         0.006887  ...  0.005271   \n",
       "av_money_spent                 0.313841         0.396038  ...  0.013244   \n",
       "num_received                   1.000000         0.516739  ...  0.073504   \n",
       "viewed/received                0.516739         1.000000  ...  0.021825   \n",
       "completed/viewed               0.337040         0.414042  ...  0.020779   \n",
       "completed_not_viewed           0.198433         0.103660  ...  0.012585   \n",
       "num_received_this              0.331111         0.176541  ...  0.019362   \n",
       "viewed/received_this           0.283436         0.251604  ...  0.051579   \n",
       "completed/viewed_this          0.134594         0.138102  ...  0.028349   \n",
       "completed_not_viewed_this      0.097160         0.036770  ... -0.001800   \n",
       "offer_0                       -0.034567        -0.011767  ... -0.117737   \n",
       "offer_1                        0.073504         0.021825  ...  1.000000   \n",
       "offer_2                        0.073351         0.022699  ... -0.130969   \n",
       "offer_3                       -0.030938        -0.009611  ... -0.118190   \n",
       "offer_4                       -0.108061        -0.035243  ... -0.104960   \n",
       "offer_5                       -0.024229        -0.002591  ... -0.117482   \n",
       "offer_6                       -0.105950        -0.042932  ... -0.102279   \n",
       "offer_7                        0.067890         0.019774  ... -0.131042   \n",
       "offer_8                        0.069505         0.027679  ... -0.129864   \n",
       "offer_9                       -0.026006        -0.005509  ... -0.118344   \n",
       "label                         -0.107171        -0.032227  ...  0.198810   \n",
       "\n",
       "                            offer_2   offer_3   offer_4   offer_5   offer_6  \\\n",
       "F                          0.001120 -0.000737  0.006749 -0.004738 -0.004614   \n",
       "M                          0.000916 -0.000871 -0.002849  0.003803  0.005320   \n",
       "O                          0.000654  0.001314  0.002979  0.002733 -0.000603   \n",
       "U                         -0.003135  0.001902 -0.006255  0.000195 -0.001151   \n",
       "age                        0.004210 -0.002300  0.002606 -0.000767 -0.000065   \n",
       "income                     0.000764 -0.003768 -0.001267 -0.000318 -0.005584   \n",
       "membership_length          0.000403  0.004939  0.000589 -0.010036  0.001721   \n",
       "av_money_spent             0.018239  0.002616 -0.019673 -0.011763 -0.036415   \n",
       "num_received               0.073351 -0.030938 -0.108061 -0.024229 -0.105950   \n",
       "viewed/received            0.022699 -0.009611 -0.035243 -0.002591 -0.042932   \n",
       "completed/viewed           0.018320 -0.007738 -0.026592 -0.009568 -0.031542   \n",
       "completed_not_viewed       0.012256 -0.000273 -0.019720 -0.003682 -0.021145   \n",
       "num_received_this          0.023672 -0.008809 -0.036359 -0.008941 -0.037468   \n",
       "viewed/received_this      -0.025867 -0.039027 -0.071535  0.019414 -0.015218   \n",
       "completed/viewed_this     -0.069690 -0.001700 -0.024854  0.053831  0.030239   \n",
       "completed_not_viewed_this -0.046904  0.047860  0.003839  0.002604 -0.016795   \n",
       "offer_0                   -0.118216 -0.106681 -0.094740 -0.106043 -0.092320   \n",
       "offer_1                   -0.130969 -0.118190 -0.104960 -0.117482 -0.102279   \n",
       "offer_2                    1.000000 -0.118671 -0.105388 -0.117960 -0.102695   \n",
       "offer_3                   -0.118671  1.000000 -0.095104 -0.106451 -0.092675   \n",
       "offer_4                   -0.105388 -0.095104  1.000000 -0.094535 -0.082302   \n",
       "offer_5                   -0.117960 -0.106451 -0.094535  1.000000 -0.092121   \n",
       "offer_6                   -0.102695 -0.092675 -0.082302 -0.092121  1.000000   \n",
       "offer_7                   -0.131575 -0.118736 -0.105446 -0.118026 -0.102753   \n",
       "offer_8                   -0.130393 -0.117670 -0.104499 -0.116966 -0.101829   \n",
       "offer_9                   -0.118825 -0.107231 -0.095229 -0.106590 -0.092796   \n",
       "label                     -0.658765  0.180141  0.159977  0.179063  0.155891   \n",
       "\n",
       "                            offer_7   offer_8   offer_9     label  \n",
       "F                          0.004370 -0.002159 -0.002574 -0.004166  \n",
       "M                         -0.004631 -0.000889  0.002432  0.002820  \n",
       "O                          0.002963 -0.001584 -0.002334 -0.002745  \n",
       "U                         -0.000275  0.004855  0.000786  0.002587  \n",
       "age                        0.005979  0.000075 -0.005924 -0.007731  \n",
       "income                     0.003583  0.002338 -0.002103 -0.003298  \n",
       "membership_length          0.001926 -0.005336 -0.000274 -0.001767  \n",
       "av_money_spent             0.021134  0.016454 -0.005191 -0.029876  \n",
       "num_received               0.067890  0.069505 -0.026006 -0.107171  \n",
       "viewed/received            0.019774  0.027679 -0.005509 -0.032227  \n",
       "completed/viewed           0.020129  0.015268 -0.010146 -0.029175  \n",
       "completed_not_viewed       0.011961  0.012478  0.000584 -0.018375  \n",
       "num_received_this          0.025908  0.026121 -0.005022 -0.037621  \n",
       "viewed/received_this       0.039592  0.055319 -0.037366 -0.010424  \n",
       "completed/viewed_this     -0.069729  0.052714 -0.001545  0.105789  \n",
       "completed_not_viewed_this -0.046930  0.026260  0.036958  0.071200  \n",
       "offer_0                   -0.118282 -0.117219 -0.106820  0.179451  \n",
       "offer_1                   -0.131042 -0.129864 -0.118344  0.198810  \n",
       "offer_2                   -0.131575 -0.130393 -0.118825 -0.658765  \n",
       "offer_3                   -0.118736 -0.117670 -0.107231  0.180141  \n",
       "offer_4                   -0.105446 -0.104499 -0.095229  0.159977  \n",
       "offer_5                   -0.118026 -0.116966 -0.106590  0.179063  \n",
       "offer_6                   -0.102753 -0.101829 -0.092796  0.155891  \n",
       "offer_7                    1.000000 -0.130465 -0.118891 -0.659131  \n",
       "offer_8                   -0.130465  1.000000 -0.117823  0.197935  \n",
       "offer_9                   -0.118891 -0.117823  1.000000  0.180376  \n",
       "label                     -0.659131  0.197935  0.180376  1.000000  \n",
       "\n",
       "[27 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the correlation matrix:\n",
    "training_data_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features does not seem to be correlated to eachother, so we keep all of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the training features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data_df.values[:, :-1].astype(np.float32)\n",
    "y = training_data_df.values[:, -1].astype(np.float32)\n",
    "\n",
    "# deleting the original dataframe:\n",
    "training_data_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffleing and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (49671, 26)\n",
      "validation size: (5520, 26)\n",
      "test size: (6133, 26)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "print('training size: {}'.format(X_train.shape))\n",
    "print('validation size: {}'.format(X_val.shape))\n",
    "print('test size: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data into torch.tensor:\n",
    "X_train = torch.as_tensor(X_train, dtype=torch.float).to(device)\n",
    "X_val = torch.as_tensor(X_val, dtype=torch.float).to(device)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float).to(device)\n",
    "\n",
    "y_train = torch.as_tensor(y_train, dtype=torch.long).to(device)\n",
    "y_val = torch.as_tensor(y_val, dtype=torch.long).to(device)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datasets for the dataloaders:\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 10\n",
    "# creating the data loaders:\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Linear Feed forward neural network:\n",
    "\n",
    "The network is defined in `source/model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING\n",
      "Epoch 0/29\n",
      "learning rate : 0.0001\n",
      "----------\n",
      "pred_labels: tensor([1, 3, 0, 0, 3, 3, 3, 0, 0, 0], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 2, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 0/4968 train accuracy : 0.3\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 2, 2, 2, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 500/4968 train accuracy : 0.6\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 1000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 1500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 2, 3, 2, 2, 3, 3], device='cuda:0')\n",
      "Iteration 2000/4968 train accuracy : 0.7\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 2, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 2500/4968 train accuracy : 0.8\n",
      "pred_labels: tensor([3, 3, 3, 3, 2, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 2, 3, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 3000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 2], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 2, 3, 3, 3, 3, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 3500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 2, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 4000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 2, 2, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 2, 3], device='cuda:0')\n",
      "Iteration 4500/4968 train accuracy : 0.8\n",
      "EPOCH 0/29 TRAIN loss/acc : 0.890/100.00%\n",
      "EPOCH 0/29 VAL loss/acc : 0.770/100.00%\n",
      "----------\n",
      "Epoch 1/29\n",
      "learning rate : 0.0001\n",
      "----------\n",
      "pred_labels: tensor([3, 2, 3, 2, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 2, 3, 2, 3, 2, 3, 3, 2, 3], device='cuda:0')\n",
      "Iteration 5000/4968 train accuracy : 0.8\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 2, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 5500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 2, 3, 3, 2, 3, 2, 2, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 2, 3, 3, 2, 3, 2, 2, 3, 3], device='cuda:0')\n",
      "Iteration 6000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 2, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 2, 3, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 6500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 2, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 2, 3, 3, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 7000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 2, 3, 3], device='cuda:0')\n",
      "Iteration 7500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 2, 3, 2, 2, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 2, 3, 2, 2, 3], device='cuda:0')\n",
      "Iteration 8000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 8500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 2, 2, 3, 2, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 2, 2, 3, 2, 3, 3, 3], device='cuda:0')\n",
      "Iteration 9000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 2, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 9500/4968 train accuracy : 1.0\n",
      "EPOCH 1/29 TRAIN loss/acc : 0.757/100.00%\n",
      "EPOCH 1/29 VAL loss/acc : 0.747/100.00%\n",
      "----------\n",
      "Epoch 2/29\n",
      "learning rate : 0.0001\n",
      "----------\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 2, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 2, 3, 3, 2, 3, 3, 3], device='cuda:0')\n",
      "Iteration 10000/4968 train accuracy : 0.8\n",
      "pred_labels: tensor([3, 3, 3, 2, 3, 2, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 2, 3, 2, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 10500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 2, 3, 3, 3, 3, 2, 3, 3, 2], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 2, 3, 3, 3, 3, 2, 3, 3, 2], device='cuda:0')\n",
      "Iteration 11000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 11500/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 12000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 12500/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 2, 3, 2, 3, 3, 3, 3, 2], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 2, 3, 2, 3, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 13000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([2, 3, 3, 3, 3, 2, 3, 3, 3, 2], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 3, 2, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 13500/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 3, 2], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 14000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 2, 3, 3, 2, 2, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 2, 3, 3, 2, 2, 3, 3], device='cuda:0')\n",
      "Iteration 14500/4968 train accuracy : 1.0\n",
      "EPOCH 2/29 TRAIN loss/acc : 0.744/100.00%\n",
      "EPOCH 2/29 VAL loss/acc : 0.744/100.00%\n",
      "----------\n",
      "Epoch 3/29\n",
      "learning rate : 0.0001\n",
      "----------\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 2, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 2, 3, 2, 3], device='cuda:0')\n",
      "Iteration 15000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 2, 3, 3, 3, 3, 3, 3, 3, 2], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 2, 3, 3, 3, 3, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 15500/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 2, 3, 3, 3, 2], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 2, 3, 3, 3, 2], device='cuda:0')\n",
      "Iteration 16000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 16500/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 2, 2, 3, 3, 2, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 2, 2, 3, 3, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 17000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 2, 3, 3, 2, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 2, 3, 3, 2, 3, 3, 3], device='cuda:0')\n",
      "Iteration 17500/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 2, 3, 3, 2, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 2, 3, 3, 2, 3, 3], device='cuda:0')\n",
      "Iteration 18000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 2, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 2, 3], device='cuda:0')\n",
      "Iteration 18500/4968 train accuracy : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 2, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 2, 3, 3, 3, 2, 3], device='cuda:0')\n",
      "Iteration 19000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 2, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 19500/4968 train accuracy : 0.9\n",
      "EPOCH 3/29 TRAIN loss/acc : 0.744/100.00%\n",
      "EPOCH 3/29 VAL loss/acc : 0.744/100.00%\n",
      "----------\n",
      "Epoch 4/29\n",
      "learning rate : 0.0001\n",
      "----------\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 2, 2, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 2, 2, 3], device='cuda:0')\n",
      "Iteration 20000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 20500/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([2, 3, 3, 3, 3, 3, 2, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 2, 3, 3, 3, 2, 3, 3, 3], device='cuda:0')\n",
      "Iteration 21000/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([2, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([2, 3, 3, 3, 3, 3, 2, 3, 3, 3], device='cuda:0')\n",
      "Iteration 21500/4968 train accuracy : 0.9\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "Iteration 22000/4968 train accuracy : 1.0\n",
      "pred_labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 2, 3], device='cuda:0',\n",
      "       grad_fn=<NotImplemented>)\n",
      "labels: tensor([3, 3, 3, 3, 3, 3, 2, 2, 2, 3], device='cuda:0')\n",
      "Iteration 22500/4968 train accuracy : 0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d7bdfcb74280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m NN_solver = solver.NN_Solver(optim_args={\"lr\": 1e-4, \"weight_decay\": 0},\n\u001b[1;32m     12\u001b[0m                 loss_func=torch.nn.CrossEntropyLoss())\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbest_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_nth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Udacity/Machine_Learning_Engineer/Starbucks_Capstone_Project/source/solver.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_loader, val_loader, num_epochs, log_nth)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0;31m# back propagation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                         \u001b[0;31m# printing the accuracy in every log_nth iteration:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/starbucks/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/starbucks/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# network parameters:\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 4\n",
    "hidden_dims = [64]\n",
    "dropout = 0.2\n",
    "\n",
    "# instantiating the model:\n",
    "model_NN = Linear_NN(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim, dropout=dropout)\n",
    "model_NN.to(device)\n",
    "\n",
    "NN_solver = solver.NN_Solver(optim_args={\"lr\": 1e-4, \"weight_decay\": 0},\n",
    "                loss_func=torch.nn.CrossEntropyLoss())\n",
    "best_state_dict = NN_solver.train(model_NN, train_loader, val_loader, log_nth=500, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "The solver class is defined in `source/solver.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are checking the implementation by overfitting ot a single data instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data into torch.tensor:\n",
    "X_train_single = torch.as_tensor(X_train[0, :].reshape(1, -1), dtype=torch.float).to(device)\n",
    "X_val_single = torch.as_tensor(X_val[0, :].reshape(1, -1), dtype=torch.float).to(device)\n",
    "\n",
    "y_train_single = torch.as_tensor(y_train[0].reshape(1), dtype=torch.long).to(device)\n",
    "y_val_single = torch.as_tensor(y_val[0].reshape(1), dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters:\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 4\n",
    "hidden_dims = [64]\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING\n",
      "Epoch 0/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.1231, 0.3584, 0.1749, 0.3436]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "Iteration 0/30 train accuracy : 0.0\n",
      "EPOCH 0/29 TRAIN loss/acc : 1.467/0.00%\n",
      "EPOCH 0/29 VAL loss/acc : 1.537/0.00%\n",
      "----------\n",
      "Epoch 1/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0764, 0.5218, 0.1069, 0.2948]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 1/29 TRAIN loss/acc : 1.546/0.00%\n",
      "EPOCH 1/29 VAL loss/acc : 1.519/0.00%\n",
      "----------\n",
      "Epoch 2/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0980, 0.4772, 0.1880, 0.2368]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 2/29 TRAIN loss/acc : 1.458/0.00%\n",
      "EPOCH 2/29 VAL loss/acc : 1.499/0.00%\n",
      "----------\n",
      "Epoch 3/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0593, 0.4584, 0.2871, 0.1952]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 3/29 TRAIN loss/acc : 1.360/0.00%\n",
      "EPOCH 3/29 VAL loss/acc : 1.477/0.00%\n",
      "----------\n",
      "Epoch 4/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.2716, 0.2770, 0.3260, 0.1255]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 4/29 TRAIN loss/acc : 1.313/100.00%\n",
      "EPOCH 4/29 VAL loss/acc : 1.453/0.00%\n",
      "----------\n",
      "Epoch 5/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.2527, 0.3076, 0.3830, 0.0566]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 5/29 TRAIN loss/acc : 1.260/100.00%\n",
      "EPOCH 5/29 VAL loss/acc : 1.428/0.00%\n",
      "----------\n",
      "Epoch 6/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.1003, 0.2570, 0.3760, 0.2667]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 6/29 TRAIN loss/acc : 1.265/100.00%\n",
      "EPOCH 6/29 VAL loss/acc : 1.400/0.00%\n",
      "----------\n",
      "Epoch 7/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.1335, 0.2504, 0.4045, 0.2116]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 7/29 TRAIN loss/acc : 1.237/100.00%\n",
      "EPOCH 7/29 VAL loss/acc : 1.369/0.00%\n",
      "----------\n",
      "Epoch 8/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0412, 0.1916, 0.7227, 0.0444]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 8/29 TRAIN loss/acc : 0.956/100.00%\n",
      "EPOCH 8/29 VAL loss/acc : 1.334/100.00%\n",
      "----------\n",
      "Epoch 9/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0783, 0.1683, 0.5274, 0.2260]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 9/29 TRAIN loss/acc : 1.124/100.00%\n",
      "EPOCH 9/29 VAL loss/acc : 1.299/100.00%\n",
      "----------\n",
      "Epoch 10/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0466, 0.1125, 0.8097, 0.0311]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 10/29 TRAIN loss/acc : 0.885/100.00%\n",
      "EPOCH 10/29 VAL loss/acc : 1.265/100.00%\n",
      "----------\n",
      "Epoch 11/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0082, 0.0526, 0.9145, 0.0247]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 11/29 TRAIN loss/acc : 0.805/100.00%\n",
      "EPOCH 11/29 VAL loss/acc : 1.231/100.00%\n",
      "----------\n",
      "Epoch 12/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0190, 0.0669, 0.8908, 0.0233]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 12/29 TRAIN loss/acc : 0.823/100.00%\n",
      "EPOCH 12/29 VAL loss/acc : 1.197/100.00%\n",
      "----------\n",
      "Epoch 13/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0588, 0.0298, 0.9055, 0.0059]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 13/29 TRAIN loss/acc : 0.812/100.00%\n",
      "EPOCH 13/29 VAL loss/acc : 1.165/100.00%\n",
      "----------\n",
      "Epoch 14/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0088, 0.0719, 0.9077, 0.0115]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 14/29 TRAIN loss/acc : 0.810/100.00%\n",
      "EPOCH 14/29 VAL loss/acc : 1.134/100.00%\n",
      "----------\n",
      "Epoch 15/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0277, 0.0518, 0.8964, 0.0242]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 15/29 TRAIN loss/acc : 0.819/100.00%\n",
      "EPOCH 15/29 VAL loss/acc : 1.105/100.00%\n",
      "----------\n",
      "Epoch 16/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0198, 0.0192, 0.9506, 0.0104]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 16/29 TRAIN loss/acc : 0.779/100.00%\n",
      "EPOCH 16/29 VAL loss/acc : 1.078/100.00%\n",
      "----------\n",
      "Epoch 17/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[5.5416e-04, 2.6200e-03, 9.9632e-01, 5.0482e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 17/29 TRAIN loss/acc : 0.746/100.00%\n",
      "EPOCH 17/29 VAL loss/acc : 1.053/100.00%\n",
      "----------\n",
      "Epoch 18/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0010, 0.0032, 0.9944, 0.0014]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 18/29 TRAIN loss/acc : 0.748/100.00%\n",
      "EPOCH 18/29 VAL loss/acc : 1.032/100.00%\n",
      "----------\n",
      "Epoch 19/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0021, 0.0025, 0.9937, 0.0018]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 19/29 TRAIN loss/acc : 0.748/100.00%\n",
      "EPOCH 19/29 VAL loss/acc : 1.013/100.00%\n",
      "----------\n",
      "Epoch 20/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[1.0534e-03, 2.0125e-03, 9.9663e-01, 3.0136e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 20/29 TRAIN loss/acc : 0.746/100.00%\n",
      "EPOCH 20/29 VAL loss/acc : 0.995/100.00%\n",
      "----------\n",
      "Epoch 21/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0190, 0.0117, 0.9620, 0.0073]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 21/29 TRAIN loss/acc : 0.771/100.00%\n",
      "EPOCH 21/29 VAL loss/acc : 0.979/100.00%\n",
      "----------\n",
      "Epoch 22/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[3.8933e-03, 4.3665e-03, 9.9091e-01, 8.3069e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 22/29 TRAIN loss/acc : 0.750/100.00%\n",
      "EPOCH 22/29 VAL loss/acc : 0.964/100.00%\n",
      "----------\n",
      "Epoch 23/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0545, 0.0868, 0.8225, 0.0362]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 23/29 TRAIN loss/acc : 0.875/100.00%\n",
      "EPOCH 23/29 VAL loss/acc : 0.949/100.00%\n",
      "----------\n",
      "Epoch 24/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[0.0112, 0.0102, 0.9750, 0.0036]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 24/29 TRAIN loss/acc : 0.761/100.00%\n",
      "EPOCH 24/29 VAL loss/acc : 0.935/100.00%\n",
      "----------\n",
      "Epoch 25/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[3.4463e-04, 5.2175e-04, 9.9898e-01, 1.5099e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 25/29 TRAIN loss/acc : 0.744/100.00%\n",
      "EPOCH 25/29 VAL loss/acc : 0.923/100.00%\n",
      "----------\n",
      "Epoch 26/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[6.0119e-04, 3.8524e-03, 9.9481e-01, 7.3458e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 26/29 TRAIN loss/acc : 0.747/100.00%\n",
      "EPOCH 26/29 VAL loss/acc : 0.913/100.00%\n",
      "----------\n",
      "Epoch 27/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[4.5058e-05, 4.4931e-04, 9.9943e-01, 7.2003e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 27/29 TRAIN loss/acc : 0.744/100.00%\n",
      "EPOCH 27/29 VAL loss/acc : 0.903/100.00%\n",
      "----------\n",
      "Epoch 28/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[1.3296e-04, 2.7257e-04, 9.9953e-01, 6.8645e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 28/29 TRAIN loss/acc : 0.744/100.00%\n",
      "EPOCH 28/29 VAL loss/acc : 0.895/100.00%\n",
      "----------\n",
      "Epoch 29/29\n",
      "learning rate : 0.005\n",
      "----------\n",
      "output: tensor([[2.7135e-04, 3.2541e-04, 9.9917e-01, 2.2895e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "lables: tensor([2], device='cuda:0')\n",
      "EPOCH 29/29 TRAIN loss/acc : 0.744/100.00%\n",
      "EPOCH 29/29 VAL loss/acc : 0.888/100.00%\n",
      "----------\n",
      "FINISH.\n",
      "Training complete in 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# testing the model by overfitting to a single data instance:\n",
    "train_dataset_single = TensorDataset(X_train_single, y_train_single)\n",
    "val_dataset_single = TensorDataset(X_val_single, y_val_single)\n",
    "train_loader_single = torch.utils.data.DataLoader(train_dataset_single,\n",
    "                                                batch_size=1, shuffle=False, num_workers=0)\n",
    "val_loader_single = torch.utils.data.DataLoader(val_dataset_single,\n",
    "                                              batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "test_model = Linear_NN(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim, dropout=dropout)\n",
    "test_model.to(device)\n",
    "NN_solver = solver.NN_Solver(optim_args={\"lr\": 5e-3, \"weight_decay\": 0},\n",
    "                loss_func=torch.nn.CrossEntropyLoss())\n",
    "best_state_dict = NN_solver.train(test_model, train_loader_single, val_loader_single, log_nth=100, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('starbucks': conda)",
   "language": "python",
   "name": "python38264bitstarbuckscondad9e38c9f842c41baadfb9dbf2b751888"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
